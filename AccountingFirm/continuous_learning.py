# -*- coding: utf-8 -*-

import json
import os
from datetime import datetime

def collect_feedback_data(original_result, corrected_result, image_path):
    """æ”¶é›†ç”¨æˆ¶åé¥‹æ•¸æ“š
    
    Args:
        original_result: OCRåŸå§‹è­˜åˆ¥çµæœ
        corrected_result: ç”¨æˆ¶ä¿®æ­£å¾Œçš„çµæœ
        image_path: åŸå§‹åœ–åƒè·¯å¾‘
    """
    feedback_dir = "feedback_data"
    os.makedirs(feedback_dir, exist_ok=True)
    
    # å‰µå»ºåé¥‹è¨˜éŒ„
    feedback = {
        "timestamp": datetime.now().isoformat(),
        "image_path": image_path,
        "original_result": original_result,
        "corrected_result": corrected_result,
        "fields_corrected": []
    }
    
    # è­˜åˆ¥å“ªäº›å­—æ®µè¢«ä¿®æ­£äº†
    total_fields = 0
    corrected_fields = 0
    
    for field in corrected_result:
        total_fields += 1
        if field in original_result and original_result[field] != corrected_result[field]:
            corrected_fields += 1
            feedback["fields_corrected"].append({
                "field_name": field,
                "original_value": original_result[field],
                "corrected_value": corrected_result[field]
            })
    
    # è¨ˆç®—æº–ç¢ºç‡
    accuracy = ((total_fields - corrected_fields) / total_fields) * 100 if total_fields > 0 else 0
    
    # ç²å–æ­·å²æ•¸æ“š
    historical_accuracy = get_historical_accuracy(feedback_dir)
    
    # è¼¸å‡ºå­¸ç¿’é€²åº¦å ±å‘Š
    print("\n=== å­¸ç¿’é€²åº¦å ±å‘Š ===")
    print(f"ç¸½æ¬„ä½æ•¸: {total_fields}")
    print(f"éœ€è¦ä¿®æ­£æ¬„ä½æ•¸: {corrected_fields}")
    print(f"ç•¶å‰è­˜åˆ¥æº–ç¢ºç‡: {accuracy:.2f}%")
    if historical_accuracy:
        print(f"æ­·å²å¹³å‡æº–ç¢ºç‡: {historical_accuracy:.2f}%")
        if accuracy > historical_accuracy:
            print("ğŸ‘ ç³»çµ±è¡¨ç¾å„ªæ–¼æ­·å²å¹³å‡")
        elif accuracy < historical_accuracy:
            print("ğŸ“ ç³»çµ±è¡¨ç¾ä½æ–¼æ­·å²å¹³å‡ï¼Œå°‡åŠ å¼·å­¸ç¿’")
    print("==================\n")
    
    # ä¿å­˜åé¥‹æ•¸æ“š
    feedback_file = os.path.join(
        feedback_dir, 
        f"feedback_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )
    with open(feedback_file, 'w', encoding='utf-8') as f:
        json.dump(feedback, f, ensure_ascii=False, indent=2)
    
    return feedback_file

def get_historical_accuracy(feedback_dir):
    """è¨ˆç®—æ­·å²å¹³å‡æº–ç¢ºç‡"""
    if not os.path.exists(feedback_dir):
        return None
        
    feedback_files = [f for f in os.listdir(feedback_dir) if f.endswith('.json')]
    if not feedback_files:
        return None
    
    total_accuracy = 0
    file_count = 0
    
    for file in feedback_files:
        try:
            with open(os.path.join(feedback_dir, file), 'r', encoding='utf-8') as f:
                feedback = json.load(f)
                total_fields = len(feedback["corrected_result"])
                corrected_fields = len(feedback["fields_corrected"])
                if total_fields > 0:
                    accuracy = ((total_fields - corrected_fields) / total_fields) * 100
                    total_accuracy += accuracy
                    file_count += 1
        except:
            continue
    
    return total_accuracy / file_count if file_count > 0 else None

def retrain_model_with_feedback(feedback_dir="feedback_data", min_samples=50):
    """ä½¿ç”¨åé¥‹æ•¸æ“šé‡æ–°è¨“ç·´æ¨¡å‹"""
    # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„æ–°åé¥‹æ•¸æ“š
    feedback_files = [f for f in os.listdir(feedback_dir) if f.endswith('.json')]
    if len(feedback_files) < min_samples:
        print(f"åé¥‹æ•¸æ“šä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {min_samples} å€‹æ¨£æœ¬æ‰èƒ½é‡æ–°è¨“ç·´")
        return False
    
    try:
        # å˜—è©¦å°å…¥æ¨¡å‹è¨“ç·´æ¨¡å¡Š
        from model_training import train_model, TENSORFLOW_AVAILABLE, SKLEARN_AVAILABLE
        
        if not TENSORFLOW_AVAILABLE or not SKLEARN_AVAILABLE:
            print("ç¼ºå°‘å¿…è¦çš„ä¾è³´é …ï¼ˆTensorFlow æˆ– scikit-learnï¼‰ã€‚")
            print("è«‹å®‰è£é€™äº›åº«ä»¥å•Ÿç”¨æ¨¡å‹è¨“ç·´åŠŸèƒ½ã€‚")
            return False
        
        # è¨“ç·´æ¨¡å‹
        success = train_model(feedback_dir)
        
        if success:
            print(f"å·²ä½¿ç”¨ {len(feedback_files)} å€‹åé¥‹æ¨£æœ¬é‡æ–°è¨“ç·´æ¨¡å‹")
        
        return success
    except ImportError:
        print("ç„¡æ³•å°å…¥æ¨¡å‹è¨“ç·´æ¨¡å¡Šã€‚è«‹ç¢ºä¿æ‰€æœ‰ä¾è³´é …å·²å®‰è£ã€‚")
        return False

def analyze_error_patterns(feedback_dir="feedback_data"):
    """åˆ†æéŒ¯èª¤æ¨¡å¼ï¼Œæ‰¾å‡ºç³»çµ±çš„å¼±é»
    
    Args:
        feedback_dir: åé¥‹æ•¸æ“šç›®éŒ„
    """
    # åŠ è¼‰æ‰€æœ‰åé¥‹æ•¸æ“š
    feedback_files = [f for f in os.listdir(feedback_dir) if f.endswith('.json')]
    if not feedback_files:
        return {"message": "æ²’æœ‰åé¥‹æ•¸æ“šå¯åˆ†æ"}
    
    # çµ±è¨ˆå„å­—æ®µçš„éŒ¯èª¤é »ç‡
    field_error_counts = {}
    total_samples = len(feedback_files)
    
    for file in feedback_files:
        with open(os.path.join(feedback_dir, file), 'r', encoding='utf-8') as f:
            feedback = json.load(f)
            
        for correction in feedback.get("fields_corrected", []):
            field_name = correction["field_name"]
            if field_name not in field_error_counts:
                field_error_counts[field_name] = 0
            field_error_counts[field_name] += 1
    
    # è¨ˆç®—éŒ¯èª¤ç‡
    error_rates = {
        field: count / total_samples * 100 
        for field, count in field_error_counts.items()
    }
    
    # æŒ‰éŒ¯èª¤ç‡æ’åº
    sorted_error_rates = sorted(
        error_rates.items(), 
        key=lambda x: x[1], 
        reverse=True
    )
    
    return {
        "total_samples": total_samples,
        "error_patterns": sorted_error_rates,
        "recommendations": [
            f"å„ªå…ˆæ”¹é€² '{field}' å­—æ®µçš„è­˜åˆ¥ï¼ŒéŒ¯èª¤ç‡ {rate:.1f}%" 
            for field, rate in sorted_error_rates[:3]
        ]
    } 